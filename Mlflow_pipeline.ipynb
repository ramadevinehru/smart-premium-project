{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0233db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800000 entries, 0 to 799999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    800000 non-null  int64  \n",
      " 1   Age                   787511 non-null  float64\n",
      " 2   Gender                800000 non-null  object \n",
      " 3   Annual Income         770140 non-null  float64\n",
      " 4   Marital Status        787664 non-null  object \n",
      " 5   Number of Dependents  726870 non-null  float64\n",
      " 6   Education Level       800000 non-null  object \n",
      " 7   Occupation            560875 non-null  object \n",
      " 8   Health Score          750551 non-null  float64\n",
      " 9   Location              800000 non-null  object \n",
      " 10  Policy Type           800000 non-null  object \n",
      " 11  Previous Claims       557198 non-null  float64\n",
      " 12  Vehicle Age           799997 non-null  float64\n",
      " 13  Credit Score          708549 non-null  float64\n",
      " 14  Insurance Duration    799998 non-null  float64\n",
      " 15  Policy Start Date     800000 non-null  object \n",
      " 16  Customer Feedback     747724 non-null  object \n",
      " 17  Smoking Status        800000 non-null  object \n",
      " 18  Exercise Frequency    800000 non-null  object \n",
      " 19  Property Type         800000 non-null  object \n",
      " 20  Premium Amount        800000 non-null  float64\n",
      "dtypes: float64(9), int64(1), object(11)\n",
      "memory usage: 128.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the test dataset\n",
    "test_file_path = \"test.csv\"  \n",
    "test_df = pd.read_csv(test_file_path)\n",
    "\n",
    "print(\"Test Dataset Info:\")\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrama\\AppData\\Local\\Temp\\ipykernel_5688\\3389536365.py:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  test_df['Policy Start Year'] = pd.to_datetime(test_df['Policy Start Date'], errors='coerce').dt.year\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "test_df['Policy Start Year'] = pd.to_datetime(test_df['Policy Start Date'], errors='coerce').dt.year\n",
    "test_df.drop(['Policy Start Date'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "test_df.fillna({\n",
    "    'Number of Dependents': test_df['Number of Dependents'].median(),\n",
    "    'Credit Score': test_df['Credit Score'].median(),\n",
    "    'Health Score': test_df['Health Score'].median(),\n",
    "    'Previous Claims': test_df['Previous Claims'].median(),\n",
    "    'Vehicle Age': test_df['Vehicle Age'].median()\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "test_df.drop(['Customer Feedback'], axis=1, inplace=True)\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "test_df = pd.get_dummies(test_df, columns=[\n",
    "    'Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', \n",
    "    'Policy Type', 'Smoking Status', 'Exercise Frequency', 'Property Type'\n",
    "], dtype=int)\n",
    "\n",
    "# Handle any remaining NaN values after encoding\n",
    "test_df.fillna(0, inplace=True)  \n",
    "\n",
    "# Feature Scaling (Standardization) for numerical variables\n",
    "test_df['Annual Income'] = (test_df['Annual Income'] - test_df['Annual Income'].mean()) / test_df['Annual Income'].std()\n",
    "test_df['Premium Amount'] = (test_df['Premium Amount'] - test_df['Premium Amount'].mean()) / test_df['Premium Amount'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features (X) for the test set\n",
    "X_test = test_df.drop(['Premium Amount'], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd43691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = joblib.load(\"xgboost_model.pkl\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e52743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics on Test Data:\n",
      "MAE: 0.99, RMSE: 1.02, R¬≤ Score: -695647471904035479730807373824.00\n"
     ]
    }
   ],
   "source": [
    "y_test_true = test_df['Premium Amount'] \n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test_true, y_test_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_true, y_test_pred))\n",
    "r2 = r2_score(y_test_true, y_test_pred)\n",
    "\n",
    "print(f\"Evaluation Metrics on Test Data:\\nMAE: {mae:.2f}, RMSE: {rmse:.2f}, R¬≤ Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a54db9",
   "metadata": {},
   "source": [
    "#bash--->  mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2b6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrama\\AppData\\Local\\Temp\\ipykernel_13488\\4226856425.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Policy Start Year'] = pd.to_datetime(df['Policy Start Date'], errors='coerce').dt.year\n",
      "2025/04/18 01:29:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.00, RMSE: 0.00, R¬≤ Score: -37354656625566768.00\n",
      "üèÉ View run secretive-tern-80 at: http://localhost:5000/#/experiments/0/runs/15cd5787219d413d87c2fcbaaaf6c9e5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Set the tracking URI\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  \n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(df):\n",
    "    # Convert 'Policy Start Date' to datetime and extract year\n",
    "    df['Policy Start Year'] = pd.to_datetime(df['Policy Start Date'], errors='coerce').dt.year\n",
    "    df.drop(['Policy Start Date'], axis=1, inplace=True)\n",
    "\n",
    "    # Handle missing values\n",
    "    df.fillna({\n",
    "        'Number of Dependents': df['Number of Dependents'].median(),\n",
    "        'Credit Score': df['Credit Score'].median(),\n",
    "        'Health Score': df['Health Score'].median(),\n",
    "        'Previous Claims': df['Previous Claims'].median(),\n",
    "        'Vehicle Age': df['Vehicle Age'].median()\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Dropping unnecessary columns\n",
    "    df.drop(['Customer Feedback'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Preprocessing the data\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Defining features and target variable\n",
    "X = df.drop(['Premium Amount'], axis=1)\n",
    "y = df['Premium Amount']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define the preprocessing for numerical and categorical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Creating a ColumnTransformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Creating a pipeline with XGBoost\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Starting an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "\n",
    "    # Training the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"R2\", r2)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "\n",
    "   \n",
    "    print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}, R¬≤ Score: {r2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
